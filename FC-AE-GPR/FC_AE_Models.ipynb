{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import time\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "import argparse\n",
    "from scipy.io import savemat\n",
    "import h5py\n",
    "\n",
    "# train autoencoder for classification with no compression in the bottleneck layer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 64 x 64 ADP FC-AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "seed = 42\n",
    "test_data_size = 0.1\n",
    "#augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat\n",
    "with h5py.File('augmentedADP_BS1_Nt64_Nc64_BW100MHz_O1_3p5_0p5.mat', 'r') as file:\n",
    "    # List all groups in the file\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "\n",
    "    # Get the data from a specific dataset\n",
    "    ADP = file['augADP'][:]\n",
    "   # loc = file['L'][:]\n",
    "    \n",
    "x_train = ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "\n",
    "# Encoder\n",
    "x = tensorflow.keras.layers.Input(shape=(64*64), name=\"encoder_input\")\n",
    "\n",
    "encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=32*32, name=\"encoder_dense_1\")(x)\n",
    "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
    "\n",
    "encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=16*16, name=\"encoder_dense_2\")(encoder_activ_layer1)\n",
    "encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2)\n",
    "\n",
    "encoder_dense_layer3 = tensorflow.keras.layers.Dense(units=4*4, name=\"encoder_dense_3\")(encoder_activ_layer2)\n",
    "encoder_output = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(encoder_dense_layer3)\n",
    "\n",
    "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tensorflow.keras.layers.Input(shape=(4*4), name=\"decoder_input\")\n",
    "\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=16*16, name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1)\n",
    "\n",
    "decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=32*32, name=\"decoder_dense_2\")(decoder_activ_layer1)\n",
    "decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2)\n",
    "\n",
    "decoder_dense_layer3 = tensorflow.keras.layers.Dense(units=64*64, name=\"decoder_dense_3\")(decoder_activ_layer2)\n",
    "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_dense_layer3)\n",
    "\n",
    "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()\n",
    "\n",
    "# Autoencoder\n",
    "ae_input = tensorflow.keras.layers.Input(shape=(64*64), name=\"AE_input\")\n",
    "ae_encoder_output = encoder(ae_input)\n",
    "ae_decoder_output = decoder(ae_encoder_output)\n",
    "\n",
    "ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "ae.compile(loss=\"mse\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "tensorboard_callback = TensorBoard(log_dir='logs')\n",
    "\n",
    "# Now, train your model\n",
    "history = ae.fit(x_train, x_train,\n",
    "          epochs=500,\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          validation_split = 0.2,\n",
    "          callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ae.save('ae_64to4_O1.h5')\n",
    "#encoder = keras.Model(input_img, encoded)\n",
    "#decoder = keras.Model(encoded,decoded)\n",
    "# loading whole model\n",
    "#from keras.models import load_model\n",
    "encoder.save('encoder_64to4_O1.h5')\n",
    "decoder.save('decoder_64to4_O1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    A = np.matrix.flatten(imageA)\n",
    "    B = np.matrix.flatten(imageB)\n",
    "  # the 'Mean Squared Error' between the two images is the\n",
    "  # sum of the squared difference between the two images;\n",
    "  # NOTE: the two images must have the same dimension\n",
    "    if (np.linalg.norm(A) == 0) or (np.linalg.norm(B) == 0):\n",
    "        err = 0\n",
    "    else:\n",
    "        err =(np.sum(np.multiply(A,B)))/(np.linalg.norm(A)*np.linalg.norm(B))\n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "with h5py.File('augmentedADP_BS1_Nt64_Nc64_BW100MHz_O1_3p5_0p5_test.mat', 'r') as file:\n",
    "    # List all groups in the file\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "\n",
    "    # Get the data from a specific dataset\n",
    "    ADP = file['ADP_test'][:]\n",
    "   # loc = file['L'][:]\n",
    "x_test = ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing AE\n",
    "# predict using trained encoder\n",
    "x_test_orig =np.reshape(x_test,[-1,64,64])\n",
    "x_test_1d =np.reshape(x_test,[-1,64*64])\n",
    "encoded_images = encoder.predict(x_test_1d)\n",
    "decoded_images = decoder.predict(encoded_images)\n",
    "decoded_images_orig = np.reshape(decoded_images, newshape=(decoded_images.shape[0], 64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "eADP  = encoded_images\n",
    "dADP = decoded_images\n",
    "\n",
    "\n",
    "\n",
    "mdic = {\"ADP\": x_test ,\"eADP\": eADP ,\"dADP\": dADP }\n",
    "savemat(\"ADP_BS1_Nt64_Nc64_BW100MHz_01_encoded.mat\", mdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32 x 32 ADP FC-AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "seed = 42\n",
    "test_data_size = 0.1\n",
    "#augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat\n",
    "with h5py.File('augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat', 'r') as file:\n",
    "    # List all groups in the file\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "\n",
    "    # Get the data from a specific dataset\n",
    "    ADP = file['augADP'][:]\n",
    "   # loc = file['L'][:]\n",
    "    \n",
    "x_train = ADP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.datasets\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Encoder\n",
    "x = tensorflow.keras.layers.Input(shape=(32*32), name=\"encoder_input\")\n",
    "\n",
    "encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=16*16, name=\"encoder_dense_1\")(x)\n",
    "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
    "\n",
    "encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=8*8, name=\"encoder_dense_2\")(encoder_activ_layer1)\n",
    "encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2)\n",
    "\n",
    "encoder_dense_layer3 = tensorflow.keras.layers.Dense(units=4*4, name=\"encoder_dense_3\")(encoder_activ_layer2)\n",
    "encoder_output = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(encoder_dense_layer3)\n",
    "\n",
    "\n",
    "\n",
    "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tensorflow.keras.layers.Input(shape=(4*4), name=\"decoder_input\")\n",
    "\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=8*8, name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1)\n",
    "\n",
    "decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=16*16, name=\"decoder_dense_2\")(decoder_activ_layer1)\n",
    "decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2)\n",
    "\n",
    "decoder_dense_layer3 = tensorflow.keras.layers.Dense(units=32*32, name=\"decoder_dense_3\")(decoder_activ_layer2)\n",
    "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_dense_layer3)\n",
    "\n",
    "\n",
    "\n",
    "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()\n",
    "\n",
    "# Autoencoder\n",
    "ae_input = tensorflow.keras.layers.Input(shape=(32*32), name=\"AE_input\")\n",
    "ae_encoder_output = encoder(ae_input)\n",
    "ae_decoder_output = decoder(ae_encoder_output)\n",
    "\n",
    "ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
    "ae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "ae.compile(loss=\"mse\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "tensorboard_callback = TensorBoard(log_dir='logs')\n",
    "\n",
    "# Now, train your model\n",
    "history = ae.fit(x_train, x_train,\n",
    "          epochs=500,\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          validation_split = 0.2,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "ae.save('ae_32to4_O1.h5')\n",
    "#encoder = keras.Model(input_img, encoded)\n",
    "#decoder = keras.Model(encoded,decoded)\n",
    "# loading whole model\n",
    "#from keras.models import load_model\n",
    "encoder.save('encoder_32to4_O1.h5')\n",
    "decoder.save('decoder_32to4_O1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "seed = 42\n",
    "test_data_size = 0.1\n",
    "#augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat\n",
    "with h5py.File('augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat', 'r') as file:\n",
    "    # List all groups in the file\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "\n",
    "    # Get the data from a specific dataset\n",
    "    ADP = file['augADP'][:]\n",
    "   # loc = file['L'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing AE\n",
    "# predict using trained encoder\n",
    "x_test = ADP\n",
    "x_test_orig =np.reshape(x_test,[-1,32,32])\n",
    "x_test_1d =np.reshape(x_test,[-1,32*32])\n",
    "encoded_images = encoder.predict(x_test_1d)\n",
    "decoded_images = decoder.predict(encoded_images)\n",
    "decoded_images_orig = numpy.reshape(decoded_images, newshape=(decoded_images.shape[0], 32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e = np.zeros(len(decoded_images_orig))\n",
    "for i, image in enumerate(decoded_images_orig):\n",
    "  e[i] = mse(image,x_test_orig[i,:,:])\n",
    "\n",
    "print(np.mean(e))\n",
    "print(np.std(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "seed = 42\n",
    "test_data_size = 0.1\n",
    "#augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat\n",
    "with h5py.File('augmentedADP_BS1_Nt32_Nc32_BW100MHz_O1_0p5.mat', 'r') as file:\n",
    "    # List all groups in the file\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "\n",
    "    # Get the data from a specific dataset\n",
    "    ADP = file['augADP'][:]\n",
    "   # loc = file['L'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 x 16 ADP FC-AE Model\n",
    "- the load, train and test are the same as in the previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.datasets\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Encoder\n",
    "x = tensorflow.keras.layers.Input(shape=(16*16), name=\"encoder_input\")\n",
    "\n",
    "encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=12*12, name=\"encoder_dense_1\")(x)\n",
    "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
    "\n",
    "encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=8*8, name=\"encoder_dense_2\")(encoder_activ_layer1)\n",
    "encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2)\n",
    "\n",
    "encoder_dense_layer3 = tensorflow.keras.layers.Dense(units=4*4, name=\"encoder_dense_3\")(encoder_activ_layer2)\n",
    "encoder_output = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(encoder_dense_layer3)\n",
    "\n",
    "\n",
    "\n",
    "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tensorflow.keras.layers.Input(shape=(4*4), name=\"decoder_input\")\n",
    "\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=8*8, name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1)\n",
    "\n",
    "decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=12*12, name=\"decoder_dense_2\")(decoder_activ_layer1)\n",
    "decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2)\n",
    "\n",
    "decoder_dense_layer3 = tensorflow.keras.layers.Dense(units=16*16, name=\"decoder_dense_3\")(decoder_activ_layer2)\n",
    "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_dense_layer3)\n",
    "\n",
    "\n",
    "\n",
    "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()\n",
    "\n",
    "# Autoencoder\n",
    "ae_input = tensorflow.keras.layers.Input(shape=(16*16), name=\"AE_input\")\n",
    "ae_encoder_output = encoder(ae_input)\n",
    "ae_decoder_output = decoder(ae_encoder_output)\n",
    "\n",
    "ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
    "ae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 x 8 ADP FC-AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.datasets\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Encoder\n",
    "x = tensorflow.keras.layers.Input(shape=(8*8), name=\"encoder_input\")\n",
    "\n",
    "encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=6*6, name=\"encoder_dense_1\")(x)\n",
    "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
    "\n",
    "encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=4*4, name=\"encoder_dense_2\")(encoder_activ_layer1)\n",
    "encoder_output = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2)\n",
    "\n",
    "\n",
    "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tensorflow.keras.layers.Input(shape=(4*4), name=\"decoder_input\")\n",
    "\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=6*6, name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1)\n",
    "\n",
    "decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=8*8, name=\"decoder_dense_2\")(decoder_activ_layer1)\n",
    "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2)\n",
    "\n",
    "\n",
    "\n",
    "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()\n",
    "\n",
    "# Autoencoder\n",
    "ae_input = tensorflow.keras.layers.Input(shape=(8*8), name=\"AE_input\")\n",
    "ae_encoder_output = encoder(ae_input)\n",
    "ae_decoder_output = decoder(ae_encoder_output)\n",
    "\n",
    "ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
